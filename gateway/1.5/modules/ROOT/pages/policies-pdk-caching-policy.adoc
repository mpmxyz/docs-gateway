= Data Chaching Policy Template
ifndef::env-site,env-github[]
include::_attributes.adoc[]
endif::[]
:imagesdir: ../assets/images

== Policy Use Case

An antique store that buys and sells items needs to track the stock of each item in its collection and who buys it. To track the inventory movement, the company uses an API. 

During business hours, the catalog changes constantly and caching the available items isn't useful. Outside of business hours, the stock is frozen, and the catalog can be cached without any concern. Given this, the manager of the antique store's server decides to implement a caching policy that caches the stock during the non-business hours. 

The policy first checks the time of each incoming request. Then, if the request is outside of business hours, the policy caches the response.

To reuse the policy, the amount of cached requests and the business hours are configurable. 

An error in the caching flow should not make a request fail. So, by default, the caching policy does not block requests.  


== Implement the Policy

To implement the policy:

. xref:policies-pdk-create-project.adoc[Create a new policy project].
. Replace the `src/gcl.yaml` file with the following snippet:
+
.Expand to view the `yaml` snippet.
[%collapsible]
====
[source, yaml]
----
---
apiVersion: gateway.mulesoft.com/v1alpha1
kind: Extension
metadata:
  labels:
    title: awesome-cache
    category: Custom
spec:
  extends:
    - name: extension-definition
  properties:
    max_cached_values:
      type: integer
      default: 100
    start_hour:
      type: integer
      default: 18
    end_hour:
      type: integer
      default: 10
  required:
    - max_cached_values
    - start_hour
    - end_hour
----
====
+
The `yaml` snippet defines the following configuration parameters:
+
* `max_cached_values`: The maximum number of response to cache
* `start_hour`: The start of non-business hours
* `end_hour`: The end of non-business hours

. Run the `build-asset-files` command to propagate the changes to the `src/generated/config.rs` rust file and the JSON schema for the UI:
+
[source,cmd]
----
make build-asset-files
----

. Add the `chrono` Rust library to the `cargo.toml` file:
+
[source,toml]
----
[dependencies]
...
chrono = {version = "0.4.26", features = ["serde"] }
----

. Replace the `src/lib.rs` with the following Rust file:
+
.Expand to view the Rust file.
[%collapsible]
====
[source,rust]
----
// Copyright 2023 Salesforce, Inc. All rights reserved.
mod generated;

use anyhow::Result;

use pdk::api::hl::*;

use crate::generated::config::Config;

use chrono::{DateTime, Days, Local, Timelike};
use serde::{Deserialize, Serialize};

/// This enum sends data from the request scope to the response scope.
enum CachingData {
    SaveResponse(String),
    IgnoreCache,
}

/// This struct serializes the response in the cache.
#[derive(Serialize, Deserialize)]
pub struct CachedResponse {
    valid_until: DateTime<Local>,
    status_code: u32,
    headers: Vec<(String, String)>,
    body: Vec<u8>,
}

impl CachedResponse {
    /// Given the current time check, if the value was cached in the current cache window.
    fn has_expired(&self, now: &DateTime<Local>) -> bool {
        self.valid_until.lt(now)
    }
}

/// Transforms the CachedResponse into a Response
impl From<CachedResponse> for Response {
    fn from(response: CachedResponse) -> Self {
        Response::new(response.status_code)
            .with_headers(response.headers)
            .with_body(response.body)
    }
}

/// Checks if the time is between the given range
fn check_time_in_range(now: u32, start: u32, end: u32) -> bool {
    logger::debug!("Checking {now} in rime range: {start}-{end}.");
    if end >= start {
        // Same day range. Eg: from 10 to 14
        now >= start && now < end
    } else {
        // Partitioned range. Eg: from 20 to 1
        now >= start || now < end
    }
}

/// Sets the given time to the specific hour setting all time subunits to 0
fn set_to_hour(time: DateTime<Local>, hour: u32) -> Result<DateTime<Local>, CachingResponseError> {
    let time = time.with_hour(hour).ok_or(CachingResponseError::Time)?;
    let time = time.with_minute(0).ok_or(CachingResponseError::Time)?;
    let time = time.with_second(0).ok_or(CachingResponseError::Time)?;
    time.with_nanosecond(0).ok_or(CachingResponseError::Time)
}

/// Given the current time, and the range when to cache, calculate until when the cached value should be valid
fn calculate_validity(
    now: DateTime<Local>,
    start: u32,
    end: u32,
) -> Result<DateTime<Local>, CachingResponseError> {
    // If we have a same day range or if we are already on the second day of a partitioned range
    if end >= start || now.hour() < start {
        set_to_hour(now, end as u32)
    } else {
        // We are on the first day of a partitioned range
        let time = now
            .checked_add_days(Days::new(1))
            .ok_or(CachingResponseError::Time)?;
        set_to_hour(time, end as u32)
    }
}

/// Defines custom request errors to handle them in an unified way
enum CachingRequestError {
    OutsideRange,
    CacheMiss(String),
    Deserialize(String, serde_json::Error),
}

/// Trys to read existing requests from the cache.
async fn try_from_cache(
    request_state: RequestState,
    config: &Config,
    cache: &impl Cache,
) -> Result<CachedResponse, CachingRequestError> {
    // Await for the headers
    let headers_state = request_state.into_headers_state().await;

    // Get the time in the current timezone.
    let now = Local::now();

    // Check if cache should be uses
    if !check_time_in_range(now.hour(), config.start_hour as u32, config.end_hour as u32) {
        return Err(CachingRequestError::OutsideRange);
    }

    // Gets the request path to use as caching key
    let path = headers_state.path();

    // Reads the value from the cache
    let cached = cache
        .get(path.as_str())
        .ok_or_else(|| CachingRequestError::CacheMiss(path.clone()))?;

    // Deserializes the retrieved data
    let deserialized: CachedResponse = serde_json::from_slice(cached.as_slice())
        .map_err(|e| CachingRequestError::Deserialize(path.clone(), e))?;

    // Checks the logical expiration of the cached value
    if deserialized.has_expired(&now) {
        return Err(CachingRequestError::CacheMiss(path));
    }

    Ok(deserialized)
}

/// Wraps the policy logic to unify the error handling
async fn request_filter(
    request_state: RequestState,
    config: &Config,
    cache: &impl Cache,
) -> Flow<CachingData> {
    match try_from_cache(request_state, config, cache).await {
        Ok(data) => {
            logger::debug!("Data retrieved from the cache.");
            Flow::Break(data.into())
        }
        Err(CachingRequestError::OutsideRange) => {
            logger::debug!("Outside caching hours. Request will proceed to the backend.");
            Flow::Continue(CachingData::IgnoreCache)
        }
        Err(CachingRequestError::CacheMiss(path)) => {
            logger::debug!("Cache Miss. Request will proceed to the backend.");
            Flow::Continue(CachingData::SaveResponse(path))
        }
        Err(CachingRequestError::Deserialize(path, error)) => {
            logger::warn!("Unexpected error deserializing the cached value. Request will proceed to the backend: {error}");
            cache.delete(path.as_str());
            Flow::Continue(CachingData::SaveResponse(path))
        }
    }
}

/// Define the custom response errors to handle them in an unified way
enum CachingResponseError {
    Serialization(serde_json::Error),
    Cache(CacheError),
    Time,
}

/// Try to save the response to the cache.
async fn save_to_cache(
    response_state: ResponseState,
    path: &str,
    config: &Config,
    cache: &impl Cache,
) -> Result<(), CachingResponseError> {
    // Awaits for the headers
    let headers_state = response_state.into_headers_state().await;
    let status_code = headers_state.status_code(); // Get the status code.
    let headers = headers_state.headers(); // Get the headers.

    // Awaits for the body
    let body_state = headers_state.into_body_state().await;
    let body = body_state.body(); // Get the body.

    // Calculates the time of logical expiration of the cached response.
    let valid_until = calculate_validity(
        Local::now(),
        config.start_hour as u32,
        config.end_hour as u32,
    )?;

    // Creates the object that we'll store in the cache.
    let response = CachedResponse {
        valid_until,
        status_code,
        headers,
        body,
    };

    // Serializes the object.
    let serialized = serde_json::to_vec(&response).map_err(CachingResponseError::Serialization)?;

    // Saves the serialized object
    cache
        .save(path, serialized)
        .map_err(CachingResponseError::Cache)?;

    Ok(())
}

/// Wraps the actual policy logic to unify the error handling.
async fn response_filter(
    response_state: ResponseState,
    RequestData(caching_data): RequestData<CachingData>,
    config: &Config,
    cache: &impl Cache,
) {
    // Check if we should save the response to the cache
    if let CachingData::SaveResponse(path) = caching_data {
        match save_to_cache(response_state, path.as_str(), config, cache).await {
            Ok(()) => {
                logger::debug!("Response successfully cached.")
            }
            Err(CachingResponseError::Serialization(error)) => {
                logger::warn!("Unexpected error serializing the response: {error}.")
            }
            Err(CachingResponseError::Cache(error)) => {
                logger::warn!("Unexpected saving the response to the cache: {error}.")
            }
            Err(CachingResponseError::Time) => {
                logger::warn!("Unexpected error calculating cache expiration time.")
            }
        }
    }
}

// Policy Configuration
#[entrypoint]
async fn configure(
    launcher: Launcher,
    Configuration(bytes): Configuration,
    cache_builder: CacheBuilder,
) -> Result<()> {
    // Deserialize the configuration
    let config: Config = serde_json::from_slice(&bytes).unwrap();

    // Create the cache
    let cache = cache_builder.build(
        "awesome-caching".to_string(),
        config.max_cached_values as usize,
    );

    let filter = on_request(|request_state| request_filter(request_state, &config, &cache))
        .on_response(|response_state, request_data| {
            response_filter(response_state, request_data, &config, &cache)
        });

    launcher.launch(filter).await?;
    Ok(())
}
----
====

. Read the function documentation provided in the Rust file.
. Edit the `src/lib.rs` to fit your needs.

== Test the Policy

To test the policy:

. Run the `build` command to compile the policy:
+
[source,ssh]
----
make build
----
+
For more information about compiling policies, see xref:policies-pdk-compile-polices.adoc[].
. Configure the ‘test/config/api.yaml’ as follows:
+
.Expand to view the `yaml` configuration example.
[%collapsible]
====
[source,yaml]
----
# Copyright 2023 Salesforce, Inc. All rights reserved.
---
apiVersion: gateway.mulesoft.com/v1alpha1
kind: ApiInstance
metadata:
  name: ingress-http
spec:
  address: http://0.0.0.0:8081
  services:
    upstream:
      address: http://backend
      routes:
        - config:
            destinationPath: /anything/echo/
  policies:
    - policyRef:
        name: awesome-caching-v1-0-impl
      config:
        max_cached_values: 10
        start_hour: 18
        end_hour: 10
----

. Configure a Flex Gateway instance to debug the policy.
+
For more information, see xref:polices-pdk-debug-local.adoc[].

. Start the Flex Gateway using the 'run' command:
+
[source,ssh]
----
make run
----
+
NOTE: The ‘run’ command starts a Flex Gateway instance inside a Docker container. By default, Docker containers use UTC as the local time. 

. Send requests to the Flex Gateway. Ues the following command as an example:
+
[source,ssh]
----
curl http://127.0.0.1:8081/catalog/1 -H "cache_check: cache_value"
----
+
If the request is sent during the configured non-business hours, the response contains the original header. If the request is sent during the configured business hours, the response is empty.
+
Adjust the configured non-business hours, to view both responses.